{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "978cf9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/28358f5748d25004b917f6595800a2dcae747fe8ce50967383763faa3a7922b7?resource=download\n",
    "# https://zenodo.org/record/3941387#.YvKkOOzMI-Q\n",
    "# preprocessing: https://towardsdatascience.com/nlp-preprocessing-with-nltk-3c04ee00edc0\n",
    "# https://www.kaggle.com/code/redwankarimsony/nlp-101-tweet-sentiment-analysis-preprocessing/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "010b7c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c449d593",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9405dc96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>post</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>coleman_liau_index</th>\n",
       "      <th>flesch_kincaid_grade_level</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>gulpease_index</th>\n",
       "      <th>gunning_fog_index</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf_wish</th>\n",
       "      <th>tfidf_without</th>\n",
       "      <th>tfidf_wonder</th>\n",
       "      <th>tfidf_work</th>\n",
       "      <th>tfidf_worri</th>\n",
       "      <th>tfidf_wors</th>\n",
       "      <th>tfidf_would</th>\n",
       "      <th>tfidf_wrong</th>\n",
       "      <th>tfidf_x200b</th>\n",
       "      <th>tfidf_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>depression</td>\n",
       "      <td>What_I_do_45</td>\n",
       "      <td>2019/08/28</td>\n",
       "      <td>I want to enjoy relationships with people but ...</td>\n",
       "      <td>2.516962</td>\n",
       "      <td>4.466233</td>\n",
       "      <td>4.462510</td>\n",
       "      <td>82.994771</td>\n",
       "      <td>76.849162</td>\n",
       "      <td>7.491760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>depression</td>\n",
       "      <td>Bleumoon_Selene</td>\n",
       "      <td>2019/08/28</td>\n",
       "      <td>I didn't ask to be here. I didn't ask to be bo...</td>\n",
       "      <td>-0.320874</td>\n",
       "      <td>1.249635</td>\n",
       "      <td>2.174573</td>\n",
       "      <td>97.817393</td>\n",
       "      <td>84.242718</td>\n",
       "      <td>6.061748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>depression</td>\n",
       "      <td>Karuderu</td>\n",
       "      <td>2019/08/28</td>\n",
       "      <td>I don't know, If i can't handle anything anymo...</td>\n",
       "      <td>0.514747</td>\n",
       "      <td>2.011439</td>\n",
       "      <td>2.431083</td>\n",
       "      <td>97.352339</td>\n",
       "      <td>81.258065</td>\n",
       "      <td>4.944700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>depression</td>\n",
       "      <td>ThisNotMyMainAcc</td>\n",
       "      <td>2019/08/28</td>\n",
       "      <td>I want to know what it feels like to feel genu...</td>\n",
       "      <td>10.483559</td>\n",
       "      <td>4.622813</td>\n",
       "      <td>9.715000</td>\n",
       "      <td>77.953517</td>\n",
       "      <td>62.728814</td>\n",
       "      <td>12.477966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>depression</td>\n",
       "      <td>edgelord3045</td>\n",
       "      <td>2019/08/28</td>\n",
       "      <td>It doesn't even matter I know this will most l...</td>\n",
       "      <td>3.233005</td>\n",
       "      <td>4.428376</td>\n",
       "      <td>4.314737</td>\n",
       "      <td>87.946027</td>\n",
       "      <td>73.266862</td>\n",
       "      <td>7.108550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.189129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 350 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit            author        date  \\\n",
       "0  depression      What_I_do_45  2019/08/28   \n",
       "1  depression   Bleumoon_Selene  2019/08/28   \n",
       "2  depression          Karuderu  2019/08/28   \n",
       "3  depression  ThisNotMyMainAcc  2019/08/28   \n",
       "4  depression      edgelord3045  2019/08/28   \n",
       "\n",
       "                                                post  \\\n",
       "0  I want to enjoy relationships with people but ...   \n",
       "1  I didn't ask to be here. I didn't ask to be bo...   \n",
       "2  I don't know, If i can't handle anything anymo...   \n",
       "3  I want to know what it feels like to feel genu...   \n",
       "4  It doesn't even matter I know this will most l...   \n",
       "\n",
       "   automated_readability_index  coleman_liau_index  \\\n",
       "0                     2.516962            4.466233   \n",
       "1                    -0.320874            1.249635   \n",
       "2                     0.514747            2.011439   \n",
       "3                    10.483559            4.622813   \n",
       "4                     3.233005            4.428376   \n",
       "\n",
       "   flesch_kincaid_grade_level  flesch_reading_ease  gulpease_index  \\\n",
       "0                    4.462510            82.994771       76.849162   \n",
       "1                    2.174573            97.817393       84.242718   \n",
       "2                    2.431083            97.352339       81.258065   \n",
       "3                    9.715000            77.953517       62.728814   \n",
       "4                    4.314737            87.946027       73.266862   \n",
       "\n",
       "   gunning_fog_index  ...  tfidf_wish  tfidf_without  tfidf_wonder  \\\n",
       "0           7.491760  ...         0.0       0.000000           0.0   \n",
       "1           6.061748  ...         0.0       0.000000           0.0   \n",
       "2           4.944700  ...         0.0       0.000000           0.0   \n",
       "3          12.477966  ...         0.0       0.000000           0.0   \n",
       "4           7.108550  ...         0.0       0.047185           0.0   \n",
       "\n",
       "   tfidf_work  tfidf_worri  tfidf_wors  tfidf_would  tfidf_wrong  tfidf_x200b  \\\n",
       "0    0.054901          0.0         0.0     0.000000          0.0          0.0   \n",
       "1    0.000000          0.0         0.0     0.000000          0.0          0.0   \n",
       "2    0.000000          0.0         0.0     0.000000          0.0          0.0   \n",
       "3    0.000000          0.0         0.0     0.000000          0.0          0.0   \n",
       "4    0.000000          0.0         0.0     0.139087          0.0          0.0   \n",
       "\n",
       "   tfidf_year  \n",
       "0    0.000000  \n",
       "1    0.000000  \n",
       "2    0.000000  \n",
       "3    0.000000  \n",
       "4    0.189129  \n",
       "\n",
       "[5 rows x 350 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit = pd.read_csv('depression_pre_features_tfidf_256.csv')\n",
    "reddit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22dba598",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I want to enjoy relationships with people but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I didn't ask to be here. I didn't ask to be bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I don't know, If i can't handle anything anymo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I want to know what it feels like to feel genu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It doesn't even matter I know this will most l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Iâ€™ve deleted all my social media and I still h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post\n",
       "0  I want to enjoy relationships with people but ...\n",
       "1  I didn't ask to be here. I didn't ask to be bo...\n",
       "2  I don't know, If i can't handle anything anymo...\n",
       "3  I want to know what it feels like to feel genu...\n",
       "4  It doesn't even matter I know this will most l...\n",
       "5  Iâ€™ve deleted all my social media and I still h..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.loc[:5, ['post']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "149fe5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets:  21209\n"
     ]
    }
   ],
   "source": [
    "print('Number of tweets: ', len(reddit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f67fb0d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to enjoy relationships with people but I can't I just don't enjoy other people's company. Every conversation feels like a burden to me. The shitty thing is, I desparately want to be able to naturally experience relationships with people. But I can't. Every day I try, but it's so exhausting, and I never feel any closer or more satisfied I guess you could say in my relationship with whoever I'm talking to.\n",
      "\n",
      "I feel like a piece of shit, because even though I WANT to like socializing, I just can't, and that means I come off as very aloof. I come off as boring. I come off as an idiot or an ass. But I mean...I can't be any other way. I just feel completely trapped in this lack of feeling, this complete lack of enthusiasm I feel.\n",
      "\n",
      "A friend of mine once was going on about something he though was amazing. I can't remember what it was. He asked me, \"Don't you think that's amazing\"? I completely understood why he thought it was amazing. I could fully acknowledge why it was amazing, but I didn't actually feel like it was amazing. I just did not give a single fuck in my heart, and believe me, I could have faked interest, but in that moment, I felt like being real. There was no way to explain it. My buddy asks me, where did this depression come from? \n",
      "\n",
      "I don't fucking know. Don't ask me. I don't get a say in it. I'd like to try to, but nothing I do works, and so why tire myself? For the future? To hopefully feel better? I'm not interested in my life anymore. I don't get to be. And I'm not going to poison my brain with pharmecuticals which themselves are extremely poorly understood by the scientific community. I'm not going to be reliant on drugs just to feel something that might be what normal is supposed to feel like. Drugs that could have averse effects on me.\n"
     ]
    }
   ],
   "source": [
    "example = reddit.at[0, 'post']\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c253f99b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i want to enjoy relationships with people but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i didn't ask to be here. i didn't ask to be bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i don't know, if i can't handle anything anymo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i want to know what it feels like to feel genu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it doesn't even matter i know this will most l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Posts\n",
       "0  i want to enjoy relationships with people but ...\n",
       "1  i didn't ask to be here. i didn't ask to be bo...\n",
       "2  i don't know, if i can't handle anything anymo...\n",
       "3  i want to know what it feels like to feel genu...\n",
       "4  it doesn't even matter i know this will most l..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowercased = []\n",
    "for post in reddit['post']:\n",
    "    post=post.lower()\n",
    "    lowercased.append(post)\n",
    "# print(lowercased)\n",
    "df_lowercased = pd.DataFrame(lowercased, columns=['Posts'])\n",
    "df_lowercased.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6286c112",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0d1c912",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i want to enjoy relationships with people but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i didnt ask to be here i didnt ask to be born ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dont know if i cant handle anything anymore ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i want to know what it feels like to feel genu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it doesnt even matter i know this will most li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Posts\n",
       "0  i want to enjoy relationships with people but ...\n",
       "1  i didnt ask to be here i didnt ask to be born ...\n",
       "2  i dont know if i cant handle anything anymore ...\n",
       "3  i want to know what it feels like to feel genu...\n",
       "4  it doesnt even matter i know this will most li..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation = []\n",
    "for post in df_lowercased['Posts']:\n",
    "    post=\"\".join([char for char in post if char not in string.punctuation])\n",
    "    punctuation.append(post)\n",
    "# print(punctuation)\n",
    "df_punctuation = pd.DataFrame(punctuation, columns=['Posts'])\n",
    "df_punctuation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a59a2ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "006733a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i want to enjoy relationships with people but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i didnt ask to be here i didnt ask to be born ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dont know if i cant handle anything anymore ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i want to know what it feels like to feel genu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it doesnt even matter i know this will most li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Posts\n",
       "0  i want to enjoy relationships with people but ...\n",
       "1  i didnt ask to be here i didnt ask to be born ...\n",
       "2  i dont know if i cant handle anything anymore ...\n",
       "3  i want to know what it feels like to feel genu...\n",
       "4  it doesnt even matter i know this will most li..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = []\n",
    "for post in df_punctuation['Posts']:\n",
    "    post=word_tokenize(post)\n",
    "    words.append(post)\n",
    "# print(words)\n",
    "df_words = pd.DataFrame(punctuation, columns=['Posts'])\n",
    "df_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "737aac84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords: \n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(\"Stopwords: \")\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07188b7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "1 columns passed, passed data had 22592 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:982\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 982\u001b[0m     columns \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_or_indexify_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:1030\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[0;32m-> 1030\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m   1031\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns passed, passed data had \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1032\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1033\u001b[0m     )\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_mi_list:\n\u001b[1;32m   1035\u001b[0m \n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 1 columns passed, passed data had 22592 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     filtered_words\u001b[38;5;241m.\u001b[39mappend(post)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# print(words)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m df_filtered_words \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPosts\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m df_filtered_words\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:721\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    717\u001b[0m         \u001b[38;5;66;03m# error: Argument 1 to \"ensure_index\" has incompatible type\u001b[39;00m\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;66;03m# \"Collection[Any]\"; expected \"Union[Union[Union[ExtensionArray,\u001b[39;00m\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;66;03m# ndarray], Index, Series], Sequence[Any]]\"\u001b[39;00m\n\u001b[1;32m    720\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[1;32m    723\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[1;32m    724\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    729\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    730\u001b[0m         arrays,\n\u001b[1;32m    731\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    734\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    735\u001b[0m     )\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:519\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    517\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[0;32m--> 519\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:883\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    880\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m    881\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m--> 883\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py:985\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    982\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[0;32m--> 985\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[1;32m    988\u001b[0m     contents \u001b[38;5;241m=\u001b[39m _convert_object_array(contents, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: 1 columns passed, passed data had 22592 columns"
     ]
    }
   ],
   "source": [
    "filtered_words = []\n",
    "for post in df_words['Posts']:\n",
    "    post = [word for word in post if word not in stop_words]\n",
    "    filtered_words.append(post)\n",
    "# print(words)\n",
    "df_filtered_words = pd.DataFrame(filtered_words, columns=['Posts'])\n",
    "df_filtered_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f02f4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_words = []\n",
    "for post in df_filtered_words['Posts']:\n",
    "    post = [porter.stem(word) for word in post]\n",
    "    stemmed_words.append(post)\n",
    "# print(words)\n",
    "df_stemmed_words = pd.DataFrame(stemmed_words, columns=['Posts'])\n",
    "df_stemmed_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2427eaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = []\n",
    "for post in df_stemmed_words['Posts']:\n",
    "    post = pos_tag(stemmed_words)\n",
    "    pos.append(post)\n",
    "# print(words)\n",
    "df_pos = pd.DataFrame(pos, columns=['Posts'])\n",
    "df_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecedf20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = reddit.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb41f198",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nThe type of reddit is: ', type(words))\n",
    "print('The type of a tweet entry is: ', type(words[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c224577",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = []\n",
    "for sentence in words:\n",
    "    total_words.append(sentence.count(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d208dc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "x = np.array(total_words)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9968a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=x, name = 'Words'))\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
